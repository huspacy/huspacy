[paths]
tagger_model = null
parser_model = null
ner_model = null

[nlp]
lang = "hu"
pipeline = ["transformer", "senter", "tagger", "morphologizer", "experimental_edit_tree_lemmatizer", "experimental_arc_predicter", "experimental_arc_labeler", "ner"]
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

[components]

[components.transformer]
source = ${paths.tagger_model}
component = "transformer"

[components.senter]
source = ${paths.parser_model}
component = "senter"
replace_listeners = ["model.tok2vec"]

[components.tagger]
source = ${paths.tagger_model}
component = "tagger"

[components.morphologizer]
source = ${paths.tagger_model}
component = "morphologizer"

[components.experimental_edit_tree_lemmatizer]
source = ${paths.tagger_model}
component = "experimental_edit_tree_lemmatizer"

[components.experimental_arc_predicter]
source = ${paths.parser_model}
component = "experimental_arc_predicter"
replace_listeners = ["model.tok2vec"]

[components.experimental_arc_labeler]
source = ${paths.parser_model}
component = "experimental_arc_labeler"
replace_listeners = ["model.tok2vec"]

[components.ner]
source = ${paths.ner_model}
component = "ner"
replace_listeners = ["model.tok2vec"]
